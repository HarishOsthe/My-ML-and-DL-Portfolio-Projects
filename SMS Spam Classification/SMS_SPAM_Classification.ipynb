{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_table(\"smsspamcollection/SMSSpamCollection\",header=None, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"]=df[0].replace(to_replace=[\"spam\",\"ham\"],value=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1  Label\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      0\n",
       "1   ham                      Ok lar... Joking wif u oni...      0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3   ham  U dun say so early hor... U c already then say...      0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_message=df[1]\n",
    "print(text_message[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular expressions to replace email, addresses, urls, phone no, other numbers, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#email replace\n",
    "processed=text_message.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailaddr')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "processed=processed.str.replace(r'http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed=processed.str.replace(r'£|\\$','moneysymb')\n",
    "\n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed=processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phonenumr')\n",
    "\n",
    "# Replace numbers with 'numbr'\n",
    "processed=processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "# Remove punctuation\n",
    "processed=processed.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "\n",
    "# Replace whites pace between terms with a single space\n",
    "processed=processed.str.replace(r'\\s+',' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed=processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change words to lower case\n",
    "processed=processed.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     go until jurong point crazy available only in ...\n",
       "1                               ok lar joking wif u oni\n",
       "2     free entry in numbr a wkly comp to win fa cup ...\n",
       "3           u dun say so early hor u c already then say\n",
       "4     nah i don t think he goes to usf he lives arou...\n",
       "5     freemsg hey there darling it s been numbr week...\n",
       "6     even my brother is not like to speak with me t...\n",
       "7     as per your request melle melle oru minnaminun...\n",
       "8     winner as a valued network customer you have b...\n",
       "9     had your mobile numbr months or more u r entit...\n",
       "10    i m gonna be home soon and i don t want to tal...\n",
       "11    six chances to win cash from numbr to numbr nu...\n",
       "12    urgent you have won a numbr week free membersh...\n",
       "13    i ve been searching for the right words to tha...\n",
       "14                    i have a date on sunday with will\n",
       "15    xxxmobilemovieclub to use your credit click th...\n",
       "16                               oh k i m watching here\n",
       "17    eh u remember how numbr spell his name yes i d...\n",
       "18    fine if that s the way u feel that s the way i...\n",
       "19    england v macedonia dont miss the goals team n...\n",
       "20             is that seriously how you spell his name\n",
       "21    i m going to try for numbr months ha ha only j...\n",
       "22       so ü pay first lar then when is da stock comin\n",
       "23    aft i finish my lunch then i go str down lor a...\n",
       "24    ffffffffff alright no way i can meet up with y...\n",
       "25    just forced myself to eat a slice i m really n...\n",
       "26                        lol your always so convincing\n",
       "27    did you catch the bus are you frying an egg di...\n",
       "28    i m back amp we re packing the car now i ll le...\n",
       "29    ahhh work i vaguely remember that what does it...\n",
       "30    wait that s still not all that clear were you ...\n",
       "31    yeah he got in at numbr and was v apologetic n...\n",
       "32                         k tell me anything about you\n",
       "33    for fear of fainting with the of all that hous...\n",
       "34    thanks for your subscription to ringtone uk yo...\n",
       "35    yup ok i go home look at the timings then i ms...\n",
       "36       oops i ll let you know when my roommate s done\n",
       "37                         i see the letter b on my car\n",
       "38                                anything lor u decide\n",
       "39    hello how s you and how did saturday go i was ...\n",
       "40    pls go ahead with watts i just wanted to be su...\n",
       "41    did i forget to tell you i want you i need you...\n",
       "42    numbr rodger burns msg we tried to call you re...\n",
       "43                                   who are you seeing\n",
       "44    great i hope you like your man well endowed i ...\n",
       "45                       no calls messages missed calls\n",
       "46         didn t you get hep b immunisation in nigeria\n",
       "47                        fair enough anything going on\n",
       "48    yeah hopefully if tyler can t do it i could ma...\n",
       "49    u don t know how stubborn i am i didn t even w...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('popular')\n",
    "# nltk.download(\"third-party\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "processed=processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing word stems using a Porter stemmer\n",
    "\n",
    "ps=nltk.PorterStemmer()\n",
    "\n",
    "processed=processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go jurong point crazi avail bugi n great world...\n",
       "1                                   ok lar joke wif u oni\n",
       "2       free entri numbr wkli comp win fa cup final tk...\n",
       "3                     u dun say earli hor u c alreadi say\n",
       "4                    nah think goe usf live around though\n",
       "5       freemsg hey darl numbr week word back like fun...\n",
       "6           even brother like speak treat like aid patent\n",
       "7       per request mell mell oru minnaminungint nurun...\n",
       "8       winner valu network custom select receivea mon...\n",
       "9       mobil numbr month u r entitl updat latest colo...\n",
       "10      gonna home soon want talk stuff anymor tonight...\n",
       "11      six chanc win cash numbr numbr numbr pound txt...\n",
       "12      urgent numbr week free membership moneysymbnum...\n",
       "13      search right word thank breather promis wont t...\n",
       "14                                            date sunday\n",
       "15      xxxmobilemovieclub use credit click wap link n...\n",
       "16                                             oh k watch\n",
       "17      eh u rememb numbr spell name ye v naughti make...\n",
       "18                             fine way u feel way gota b\n",
       "19      england v macedonia dont miss goal team news t...\n",
       "20                                     serious spell name\n",
       "21                          go tri numbr month ha ha joke\n",
       "22                         ü pay first lar da stock comin\n",
       "23      aft finish lunch go str lor ard numbr smth lor...\n",
       "24                     ffffffffff alright way meet sooner\n",
       "25      forc eat slice realli hungri tho suck mark get...\n",
       "26                                      lol alway convinc\n",
       "27      catch bu fri egg make tea eat mom left dinner ...\n",
       "28                        back amp pack car let know room\n",
       "29                    ahhh work vagu rememb feel like lol\n",
       "                              ...                        \n",
       "5542                           armand say get ass epsilon\n",
       "5543                  u still havent got urself jacket ah\n",
       "5544    take derek amp taylor walmart back time done l...\n",
       "5545                               hi durban still number\n",
       "5546                               ic lotta childporn car\n",
       "5547    contract mobil numbr mnth latest motorola noki...\n",
       "5548                                        tri weekend v\n",
       "5549    know wot peopl wear shirt jumper hat belt know...\n",
       "5550                                  cool time think get\n",
       "5551                           wen get spiritu deep great\n",
       "5552    safe trip nigeria wish happi soon compani shar...\n",
       "5553                                hahaha use brain dear\n",
       "5554    well keep mind got enough ga one round trip ba...\n",
       "5555    yeh indian nice tho kane bit shud go numbr dri...\n",
       "5556                            ye u text pshew miss much\n",
       "5557    meant calcul lt gt unit lt gt school realli ex...\n",
       "5558                                     sorri call later\n",
       "5559                       next lt gt hour imma flip shit\n",
       "5560                                 anyth lor juz us lor\n",
       "5561                get dump heap mom decid come low bore\n",
       "5562    ok lor soni ericsson salesman ask shuhui say q...\n",
       "5563                               ard numbr like dat lor\n",
       "5564                     wait til least wednesday see get\n",
       "5565                                              huh lei\n",
       "5566    remind onumbr get numbr pound free call credit...\n",
       "5567    numbrnd time tri numbr contact u u moneysymbnu...\n",
       "5568                              ü b go esplanad fr home\n",
       "5569                                    piti mood suggest\n",
       "5570    guy bitch act like interest buy someth els nex...\n",
       "5571                                       rofl true name\n",
       "Name: 1, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating bag of words\n",
    "\n",
    "all_words=[]\n",
    "\n",
    "for message in processed:\n",
    "    words=word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 6576\n",
      "Most common words: [('numbr', 2647), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n"
     ]
    }
   ],
   "source": [
    "#print the total number of words and the 15 most common words\n",
    "\n",
    "print(f\"Number of words: {len(all_words)}\")\n",
    "print(f\"Most common words: {all_words.most_common(15)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 1500 most common words as features\n",
    "word_features=list(all_words.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "jurong\n",
      "point\n",
      "crazi\n",
      "avail\n",
      "bugi\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "cine\n",
      "got\n",
      "amor\n",
      "wat\n"
     ]
    }
   ],
   "source": [
    "# define a features function\n",
    "\n",
    "def find_features(message):\n",
    "    words=word_tokenize(message)\n",
    "    features={}\n",
    "    for word in word_features:\n",
    "        features[word]=(word in words)\n",
    "    return features\n",
    "\n",
    "# lets see some results\n",
    "features=find_features(processed[0])\n",
    "\n",
    "for key,value in features.items():\n",
    "    if value== True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi avail bugi n great world la e buffet cine got amor wat'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazi',\n",
       " 'avail',\n",
       " 'bugi',\n",
       " 'n',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'e',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amor',\n",
       " 'wat']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find features for all messages\n",
    "\n",
    "messages=list(zip(processed,df[\"Label\"].values))\n",
    "\n",
    "np.random.seed=123\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "#call find_features function for each SMS message\n",
    "\n",
    "featuresets=[(find_features(text),label) for (text,label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# we can split the featuresets into training and testing datasets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifiers with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KNN',\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "             weights='uniform')),\n",
       " ('decision Tree',\n",
       "  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "              splitter='best')),\n",
       " ('Random Forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False)),\n",
       " ('Logistic Regression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "            tol=0.0001, verbose=0, warm_start=False)),\n",
       " ('SGD Classifier',\n",
       "  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "         early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "         l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
       "         n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "         power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "         validation_fraction=0.1, verbose=0, warm_start=False)),\n",
       " ('Naive Bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)),\n",
       " ('SVM Linear', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=[\"KNN\",\"decision Tree\",\"Random Forest\",\"Logistic Regression\",\"SGD Classifier\",\"Naive Bayes\",\"SVM Linear\"]\n",
    "\n",
    "classifiers=[\n",
    "    KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "    LogisticRegression(),SGDClassifier(max_iter=100),MultinomialNB(),\n",
    "    SVC(kernel=\"linear\")\n",
    "]\n",
    "\n",
    "models=list(zip(names, classifiers))\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Acc: 93.03661162957646\n",
      "decision Tree: Acc: 96.62598707824839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Acc: 97.70279971284997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Acc: 98.42067480258436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier: Acc: 97.91816223977028\n",
      "Naive Bayes: Acc: 97.91816223977028\n",
      "SVM Linear: Acc: 98.1335247666906\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model=SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    print(f\"{name}: Acc: {nltk.classify.accuracy(nltk_model,testing)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 98.27709978463747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names=[\"KNN\",\"decision Tree\",\"Random Forest\",\"Logistic Regression\",\"SGD Classifier\",\"Naive Bayes\",\"SVM Linear\"]\n",
    "\n",
    "classifiers=[\n",
    "    KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "    LogisticRegression(),SGDClassifier(max_iter=100),MultinomialNB(),\n",
    "    SVC(kernel=\"linear\")\n",
    "]\n",
    "\n",
    "models=list(zip(names,classifiers))\n",
    "\n",
    "nltk_ensemble=SklearnClassifier(VotingClassifier(estimators=models, voting=\"hard\", n_jobs=-1))\n",
    "nltk_ensemble.train(training)\n",
    "print(f\"Acc: {nltk.classify.accuracy(nltk_ensemble,testing)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-8b8fa812f6ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtxt_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "txt_features, labels=[i for i in testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "txt_features=[]\n",
    "labels=[]\n",
    "while i != len(testing):\n",
    "    txt_features.append(testing[i][0])\n",
    "    labels.append(testing[i][1])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1190\n",
      "           1       0.99      0.89      0.94       203\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1393\n",
      "   macro avg       0.99      0.94      0.96      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1188</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>22</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1188    2\n",
       "       spam        22  181"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(labels,prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index=[[\"actual\",\"actual\"],[\"ham\",\"spam\"]],\n",
    "    columns=[[\"predicted\",\"predicted\"],[\"ham\",\"spam\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
